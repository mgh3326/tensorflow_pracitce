{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-7e91936c7278>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "''' GAN 모델 구성하기 '''\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "# 실제 이미지는 28 * 28 = 784개의 특징을 가집니다.\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# 가짜 이미지를 위해 필요한 노이즈의 크기는 128입니다.\n",
    "Z = tf.placeholder(tf.float32, [None, 128])\n",
    "\n",
    "# 생성자: 128(노이즈) → 256(은닉층) → 784(입력층)\n",
    "G_W1 = tf.Variable(tf.random_normal([128, 256], stddev=0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([256]))\n",
    "G_W2 = tf.Variable(tf.random_normal([256, 784], stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([784]))\n",
    "\n",
    "# 구분자: 784(입력층) → 256(은닉층) → 0 ~ 1(일치도)\n",
    "D_W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([256]))\n",
    "D_W2 = tf.Variable(tf.random_normal([256, 1], stddev=0.01))\n",
    "D_b2 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "# 생성자 객체를 생성하는 함수입니다.\n",
    "def generator(noise):\n",
    "    hidden = tf.nn.relu(tf.matmul(noise, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)\n",
    "    return output\n",
    "\n",
    "# 구분자 객체를 생성하는 함수입니다.\n",
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)\n",
    "    return output\n",
    "\n",
    "# 무작위 노이즈를 생성합니다.\n",
    "def get_noise(batch_size, noise):\n",
    "    return np.random.normal(size=(batch_size, noise))\n",
    "\n",
    "# 가짜 이미지 생성자는 128 크기의 노이즈에서 불러옵니다.\n",
    "G = generator(Z)\n",
    "# 가짜 이미지 구분자는 128 크기의 노이즈가 생성한 784 크기의 이미지에서 불러옵니다.\n",
    "D_gene = discriminator(G)\n",
    "# 실제 이미지 구분자는 784 크기의 이미지에서 불러옵니다.\n",
    "D_real = discriminator(X)\n",
    "\n",
    "# 구분자의 손실 함수는 진짜 이미지가 1에 가깝고, 가짜 이미지가 0에 가깝도록 설정합니다.\n",
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))\n",
    "# 생성자의 손실 함수는 가짜 이미지가 1에 가깝도록 설정합니다.\n",
    "loss_G = tf.reduce_mean(tf.log(D_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' GAN 모델 학습 준비하기 '''\n",
    "\n",
    "# 구분자는 구분자 가중치 및 바이어스만을 사용합니다.\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "# 생성자는 생성자 가중치 및 바이어스만을 사용합니다.\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
    "\n",
    "# 구분자 최적화를 진행합니다.\n",
    "train_D = tf.train.AdamOptimizer(0.001).minimize(-loss_D, var_list=D_var_list)\n",
    "# 생성자 최적화를 진행합니다.\n",
    "train_G = tf.train.AdamOptimizer(0.001).minimize(-loss_G, var_list=G_var_list)\n",
    "\n",
    "# 세션을 생성해 그래프를 동작시킵니다.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 구분자와 생성자의 비용 변수를 생성합니다.\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "# 배치 크기를 100으로 설정합니다.\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습: 0000 구분자 오차: -0.3718 생성자 오차: -3.343\n",
      "학습: 0001 구분자 오차: -0.1736 생성자 오차: -5.947\n",
      "학습: 0002 구분자 오차: -0.08865 생성자 오차: -5.5\n",
      "학습: 0003 구분자 오차: -0.6135 생성자 오차: -5.729\n",
      "학습: 0004 구분자 오차: -0.1609 생성자 오차: -5.075\n",
      "학습: 0005 구분자 오차: -0.3523 생성자 오차: -3.03\n",
      "학습: 0006 구분자 오차: -0.4022 생성자 오차: -4.839\n",
      "학습: 0007 구분자 오차: -1.069 생성자 오차: -2.47\n",
      "학습: 0008 구분자 오차: -0.7203 생성자 오차: -2.873\n",
      "학습: 0009 구분자 오차: -0.826 생성자 오차: -2.835\n",
      "학습: 0010 구분자 오차: -1.276 생성자 오차: -2.782\n",
      "학습: 0011 구분자 오차: -0.631 생성자 오차: -3.139\n",
      "학습: 0012 구분자 오차: -1.496 생성자 오차: -1.578\n",
      "학습: 0013 구분자 오차: -0.9282 생성자 오차: -2.917\n",
      "학습: 0014 구분자 오차: -0.8063 생성자 오차: -3.007\n",
      "학습: 0015 구분자 오차: -0.9619 생성자 오차: -2.891\n",
      "학습: 0016 구분자 오차: -0.9439 생성자 오차: -2.299\n",
      "학습: 0017 구분자 오차: -0.7772 생성자 오차: -2.89\n",
      "학습: 0018 구분자 오차: -0.8019 생성자 오차: -2.157\n",
      "학습: 0019 구분자 오차: -0.9196 생성자 오차: -2.109\n",
      "학습: 0020 구분자 오차: -0.6557 생성자 오차: -2.521\n",
      "학습: 0021 구분자 오차: -0.7813 생성자 오차: -2.575\n",
      "학습: 0022 구분자 오차: -0.9912 생성자 오차: -2.173\n",
      "학습: 0023 구분자 오차: -0.7456 생성자 오차: -2.4\n",
      "학습: 0024 구분자 오차: -0.5747 생성자 오차: -2.734\n",
      "학습: 0025 구분자 오차: -1.04 생성자 오차: -2.22\n",
      "학습: 0026 구분자 오차: -0.6839 생성자 오차: -2.046\n",
      "학습: 0027 구분자 오차: -0.7585 생성자 오차: -2.175\n",
      "학습: 0028 구분자 오차: -0.4924 생성자 오차: -2.969\n",
      "학습: 0029 구분자 오차: -1.06 생성자 오차: -1.935\n",
      "학습: 0030 구분자 오차: -0.9172 생성자 오차: -2.388\n",
      "학습: 0031 구분자 오차: -0.7476 생성자 오차: -2.48\n",
      "학습: 0032 구분자 오차: -0.6325 생성자 오차: -2.253\n",
      "학습: 0033 구분자 오차: -0.5897 생성자 오차: -2.496\n",
      "학습: 0034 구분자 오차: -0.7159 생성자 오차: -2.243\n",
      "학습: 0035 구분자 오차: -0.7714 생성자 오차: -2.415\n",
      "학습: 0036 구분자 오차: -0.5718 생성자 오차: -2.301\n",
      "학습: 0037 구분자 오차: -0.688 생성자 오차: -2.577\n",
      "학습: 0038 구분자 오차: -0.7858 생성자 오차: -1.752\n",
      "학습: 0039 구분자 오차: -1.014 생성자 오차: -1.786\n",
      "학습: 0040 구분자 오차: -0.7228 생성자 오차: -2.243\n",
      "학습: 0041 구분자 오차: -0.7119 생성자 오차: -2.153\n",
      "학습: 0042 구분자 오차: -0.7606 생성자 오차: -2.053\n",
      "학습: 0043 구분자 오차: -0.7534 생성자 오차: -1.942\n",
      "학습: 0044 구분자 오차: -0.7891 생성자 오차: -1.88\n",
      "학습: 0045 구분자 오차: -0.7736 생성자 오차: -2.047\n",
      "학습: 0046 구분자 오차: -0.6836 생성자 오차: -2.046\n",
      "학습: 0047 구분자 오차: -0.7971 생성자 오차: -2.045\n",
      "학습: 0048 구분자 오차: -0.8239 생성자 오차: -2.17\n",
      "학습: 0049 구분자 오차: -0.7521 생성자 오차: -1.845\n",
      "학습: 0050 구분자 오차: -0.8511 생성자 오차: -2.096\n",
      "학습: 0051 구분자 오차: -0.7867 생성자 오차: -1.632\n",
      "학습: 0052 구분자 오차: -0.7911 생성자 오차: -1.896\n",
      "학습: 0053 구분자 오차: -0.832 생성자 오차: -1.806\n",
      "학습: 0054 구분자 오차: -0.7739 생성자 오차: -2.505\n",
      "학습: 0055 구분자 오차: -1.024 생성자 오차: -2.026\n",
      "학습: 0056 구분자 오차: -0.8188 생성자 오차: -1.996\n",
      "학습: 0057 구분자 오차: -0.8682 생성자 오차: -1.923\n",
      "학습: 0058 구분자 오차: -0.7862 생성자 오차: -2.136\n",
      "학습: 0059 구분자 오차: -0.7137 생성자 오차: -2.282\n",
      "학습: 0060 구분자 오차: -0.8713 생성자 오차: -2.25\n",
      "학습: 0061 구분자 오차: -0.9238 생성자 오차: -2.15\n",
      "학습: 0062 구분자 오차: -0.9201 생성자 오차: -1.997\n",
      "학습: 0063 구분자 오차: -0.8061 생성자 오차: -1.901\n",
      "학습: 0064 구분자 오차: -0.7616 생성자 오차: -1.94\n",
      "학습: 0065 구분자 오차: -0.7238 생성자 오차: -2.096\n",
      "학습: 0066 구분자 오차: -0.8055 생성자 오차: -2.175\n",
      "학습: 0067 구분자 오차: -0.7412 생성자 오차: -2.162\n",
      "학습: 0068 구분자 오차: -0.8021 생성자 오차: -1.913\n",
      "학습: 0069 구분자 오차: -0.6743 생성자 오차: -1.957\n",
      "학습: 0070 구분자 오차: -0.6493 생성자 오차: -2.371\n",
      "학습: 0071 구분자 오차: -0.6719 생성자 오차: -2.279\n",
      "학습: 0072 구분자 오차: -0.7568 생성자 오차: -2.032\n",
      "학습: 0073 구분자 오차: -0.7455 생성자 오차: -2.256\n",
      "학습: 0074 구분자 오차: -0.7605 생성자 오차: -2.164\n",
      "학습: 0075 구분자 오차: -0.6735 생성자 오차: -2.191\n",
      "학습: 0076 구분자 오차: -0.6994 생성자 오차: -2.42\n",
      "학습: 0077 구분자 오차: -0.5773 생성자 오차: -2.213\n",
      "학습: 0078 구분자 오차: -0.6846 생성자 오차: -2.45\n",
      "학습: 0079 구분자 오차: -0.6177 생성자 오차: -2.318\n",
      "학습: 0080 구분자 오차: -0.6042 생성자 오차: -2.359\n",
      "학습: 0081 구분자 오차: -0.728 생성자 오차: -2.057\n",
      "학습: 0082 구분자 오차: -0.5747 생성자 오차: -2.359\n",
      "학습: 0083 구분자 오차: -0.714 생성자 오차: -2.035\n",
      "학습: 0084 구분자 오차: -0.8529 생성자 오차: -2.178\n",
      "학습: 0085 구분자 오차: -0.7303 생성자 오차: -2.488\n",
      "학습: 0086 구분자 오차: -0.7138 생성자 오차: -2.218\n",
      "학습: 0087 구분자 오차: -0.7479 생성자 오차: -2.411\n",
      "학습: 0088 구분자 오차: -0.601 생성자 오차: -2.196\n",
      "학습: 0089 구분자 오차: -0.7025 생성자 오차: -2.256\n",
      "학습: 0090 구분자 오차: -0.6246 생성자 오차: -2.349\n",
      "학습: 0091 구분자 오차: -0.9143 생성자 오차: -2.217\n",
      "학습: 0092 구분자 오차: -0.8087 생성자 오차: -2.104\n",
      "학습: 0093 구분자 오차: -0.7858 생성자 오차: -2.15\n",
      "학습: 0094 구분자 오차: -0.4688 생성자 오차: -2.935\n",
      "학습: 0095 구분자 오차: -0.7233 생성자 오차: -1.991\n",
      "학습: 0096 구분자 오차: -0.7149 생성자 오차: -2.168\n",
      "학습: 0097 구분자 오차: -0.6914 생성자 오차: -2.465\n",
      "학습: 0098 구분자 오차: -0.6518 생성자 오차: -2.222\n",
      "학습: 0099 구분자 오차: -0.655 생성자 오차: -2.502\n"
     ]
    }
   ],
   "source": [
    "''' GAN 모델 학습 수행 및 이미지 결과 확인하기 '''\n",
    "\n",
    "# 총 100번 학습을 진행합니다.\n",
    "for epoch in range(100):\n",
    "    # 전체 배치 크기만큼 반복합니다.\n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, 128)\n",
    "        # 구분자는 실제 이미지 및 노이즈를 이용해 학습을 진행합니다.\n",
    "        _, loss_val_D = sess.run([train_D, loss_D], feed_dict={X: batch_x, Z: noise})\n",
    "        # 생성자는 노이즈만을 이용해 학습을 진행합니다.\n",
    "        _, loss_val_G = sess.run([train_G, loss_G], feed_dict={Z: noise})\n",
    "    # 1번 돌 때마다 학습 상황을 출력합니다.\n",
    "    print('학습:', '%04d' % epoch,\n",
    "          '구분자 오차: {:.4}'.format(loss_val_D),\n",
    "          '생성자 오차: {:.4}'.format(loss_val_G))\n",
    "    \n",
    "    # 10번 돌 때마다 결과를 그림으로 확인합니다.\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        # 샘플 이미지의 크기는 10입니다.\n",
    "        size = 10\n",
    "        noise = get_noise(size, 128)\n",
    "\n",
    "        # 생성자가 임의의 샘플 이미지를 생성하도록 합니다.\n",
    "        samples = sess.run(G, feed_dict={Z: noise})\n",
    "        \n",
    "        # 만든 그림을 폴더에 출력할 수 있도록 합니다.\n",
    "        fig, ax = plt.subplots(1, size, figsize=(size, 1))\n",
    "        for i in range(size):\n",
    "            ax[i].set_axis_off()\n",
    "            # 28 * 28 크기의 이미지를 생성합니다.\n",
    "            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "        plt.savefig('samples/{}.png'.format(str(epoch).zfill(4)), bbox_inches='tight')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
